# Ollama JupyterLab AI Assistant Documentation

Welcome to the documentation for the Ollama JupyterLab AI Assistant. This documentation provides comprehensive information about the features, installation, usage, and development of the extension.

## Documentation Sections

- [User Guide](user-guide/README.md): Learn how to use the AI Assistant in your JupyterLab environment
- [Developer Guide](developer-guide/README.md): Information for developers who want to contribute or customize the extension
- [API Reference](api-reference/README.md): Technical reference for the extension's APIs
- [Tutorials](tutorials/README.md): Step-by-step tutorials for common tasks

## About the Project

The Ollama JupyterLab AI Assistant is an extension for JupyterLab that integrates Ollama's large language models directly into your JupyterLab environment. This allows you to:

- Chat with AI models for assistance with coding and research
- Analyze your notebook code for insights and suggestions
- Generate improvements for your existing code
- All processing happens locally using Ollama, ensuring your data stays private

## Key Features

- **Chat Interface**: Interactive chat with AI models for coding assistance
- **Code Analysis**: Get insights about your notebook code
- **Code Improvement**: Generate suggestions to improve your code
- **Local Processing**: All AI processing happens on your local machine through Ollama
- **Multiple Models**: Support for various Ollama models
- **Responsive Design**: Clean interface that adapts to different screen sizes
- **Session Management**: Save, export, and import conversations
- **Code Execution**: Run generated code directly from the assistant

## Quick Links

- [Installation Guide](user-guide/installation.md)
- [Getting Started](user-guide/getting-started.md)
- [Configuration Options](user-guide/configuration.md)
- [Troubleshooting](user-guide/troubleshooting.md)
- [Contributing to the Project](developer-guide/contributing.md)
- [Code Architecture](developer-guide/architecture.md) 