[build-system]
requires = ["jupyter_packaging~=0.12.0", "jupyterlab~=4.0"]
build-backend = "jupyter_packaging.build_api"

[tool.jupyter-packaging.options]
skip-if-exists = ["ollama_jupyter_ai/static/package.json"]
ensured-targets = ["ollama_jupyter_ai/static/package.json"]

[tool.jupyter-packaging.builder]
factory = "jupyter_packaging.npm_builder"

[tool.jupyter-packaging.build-args]
build_cmd = "build:prod"
npm = ["jlpm"]

# Add data-files section for labextension installation
[tool.jupyter-packaging.data-files]
"share/jupyter/labextensions/ollama-jupyter-ai" = [
    "ollama_jupyter_ai/static/**/*",
    "install.json"
]

# PyPI project metadata
[project]
name = "bhumukul-ollama-jupyter-ai"
version = "1.0.0.dev1"
description = "AI-powered JupyterLab extension using Ollama for local LLM integration"
readme = "README.md"
authors = [
    {name = "Bhumukul Raj"}
]
license = {text = "MIT"}
requires-python = ">=3.8"
classifiers = [
    "Framework :: Jupyter",
    "Framework :: Jupyter :: JupyterLab",
    "Framework :: Jupyter :: JupyterLab :: 4",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.8",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11"
]
keywords = ["Jupyter", "JupyterLab", "JupyterLab4", "Ollama", "AI", "Assistant"]
dependencies = [
    "jupyterlab>=4.0.0,<5.0.0"
]

# Add entry points for automatic discovery
[project.entry-points."jupyter_labextension"]
"bhumukul-ollama-jupyter-ai" = "ollama_jupyter_ai:_jupyter_labextension_paths"

[project.urls]
Homepage = "https://github.com/bhumukul-raj/ollama-ai-assistant-project"
Bug_Tracker = "https://github.com/bhumukul-raj/ollama-ai-assistant-project/issues"

[tool.check-manifest]
ignore = ["ollama_jupyter_ai/labextension/**", "yarn.lock", ".*", "package-lock.json"] 